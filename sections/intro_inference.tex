\chapter{Phylogenetic {codon} models inference}
{
	\hypersetup{linkcolor=GREYDARK}
	\minitoc
}
\label{sec:phylo_codon_models}

Given a set of observed protein-coding \acrshort{DNA} sequences in different species or lineages, the goal is to estimates the underlying parameters of evolution.
The first step to this endeavour is to define how \gls{substitution} rates are parameterized in terms of mutation, selection and drift, which is the focus of section \ref{sec-intro:codon-models}.
However, once defined, such models are not sufficient infer and estimate parameters of evolution, but instead can be used to generate a random trajectory of protein-coding \acrshort{DNA} sequence evolution.
Indeed, given parameters of evolution, simulations using the \gls{substitution} rates between \glspl{codon}, when run along a phylogenetic tree, can give us a likely representative protein coding \acrshort{DNA} sequence for each extant species (at the tip of the tree), producing an alignment.
Moreover by running several random simulations, one can expect to obtain representative and likely set of alignments.
Unfortunately, even with huge amount of simulations, it is very unlikely to generate precisely our observed alignment, and even more difficult to precisely pin down the probability of our observed alignment to have been generate by a given set of parameters.
Deriving this probability of observing a specific alignment given the parameters is thus the first theoretical question to answer, which is the focus of section \ref{sec-intro:likelihood}.
With this analytical probability obtained, it is then possible the derive for different sets of parameters their respective probability of generating the observed alignment.
The next endeavor is thus to reverse the question, and instead of having the probability of the alignement given the parameters, the goal is to derive the probability of the parameters given the alignment.
This subsequent endeavor is thus the focus of section \ref{sec-intro:bayesian}, recalling theoretical and computational implementation of Bayesian inference, in the context of phylogenetic \gls{codon} models.

\section{Phylogenetic {codon} models}
\label{sec-intro:codon-models}

\subsection{Classical {codon} models}

Under the approximation that selection occurs for protein, designing \gls{substitution} models at the amino-acid level has the major shortcoming of not taking into account that the underlying mutation process occurs at the nucleotide level.
Conversely, studying evolution of protein coding \acrshort{DNA} sequences only at the nucleotide level, while disregarding the genetic code neglects the consequences that nucleotide variation can have onto protein sequences.
These shortcomings are both addressed by \gls{codon} models, where the complexity of the genetic code is seen as an asset rather than an encumbrance.
Indeed the redundancy in the genetic code can be leveraged to disentangle mutation and selection in protein coding \acrshort{DNA} sequences, under the approximation that selection occurs at the protein level in first approximation, while the mutation process occurs at the \acrshort{DNA} level.
The genetic code allows to split mutations into synonymous and non-synonymous mutations, where synonymous mutations are deemed \gls{neutral}, and non-synonymous mutations are considered under selection~\citep{Muse1994,Goldman1994}.

Following the formalism of \gls{codon} models pioneered by \citet{Muse1994}, the $4 \times 4$ mutation matrix $\Mutmatrix$ at the nucleotide level is defined as:
\begin{equation}
	\label{eq:mutrates}
	\Mutmatrix = \begin{pmatrix}
					 - & {\mutmatrix_{AC}} & 		{\mutmatrix_{AG}} & 		{\mutmatrix_{AT}} \\
					 {\mutmatrix_{AC}} & - & {\mutmatrix_{CG}} &		{\mutmatrix_{CT}} \\
					 {\mutmatrix_{AG}} & 		{\mutmatrix_{CG}} & - & {\mutmatrix_{GT}} \\
					 {\mutmatrix_{AT}} & 		{\mutmatrix_{CT}} & 		{\mutmatrix_{GT}} & -
	\end{pmatrix},
\end{equation}
Grouping nucleotides into \glspl{codon}, mutation rate from \gls{codon} $\ci$ to $\cj$ thus depends on the underlying nucleotide change between the \gls{codon}, if $\ci$ to $\cj$ are only a mutation away, $\nucitoj$ denotes the nucleotide change between the \glspl{codon} and the mutation rate from \gls{codon} $\ci$ to $\cj$ is:
\begin{equation}
	\mu_{\itoj} =
	\begin{dcases}
		\mutmatrix_{\nucitoj} \text{ if $\ci$ and $\cj$ are one mutation away,} \\
		0 \text{ else.}
	\end{dcases}
\end{equation}

At the \gls{codon} level, synonymous mutations are deemed \gls{neutral} and the rate of \glspl{synonymous} ${\submatrix_{\itoj}}$ is equal to the mutation rate:
\begin{align}
	\submatrix_{\itoj} & = \mu_{\itoj} \\
	& = \mutmatrix_{\nucitoj}
\end{align}

Conversely, non-synonymous mutations are considered under selection, where their probability of fixation is stretched by a factor $\omega$, and their \gls{substitution} rate is:
\begin{align}
	\submatrix_{\itoj} & = \omega \mu_{\itoj} \\
	& = \omega \mutmatrix_{\nucitoj}.
\end{align}
All non-synonymous mutations are considered equivalent, and $\omega$ encompass the average strength of selection exercised on them.
Most importantly, $\omega>1$ is absorbing the signals of an excess in the rate of \glspl{non-synonymous}, indicating that the protein is under adaptive evolution.
Conversely, a default of \glspl{non-synonymous}, leading to $\omega<1$, means the protein is under purifying selection.


Because of this definition, $\omega$ identifies with the rate of \glspl{non-synonymous} over the rate of \glspl{synonymous}, termed $\dnds$.

Throughout this manuscript, the term $\dnds$ will be used to identify the estimation of $\omega$ from protein coding \acrshort{DNA} sequence alignment under the original model of \citet{Muse1994}.
To note, $\omega$ can also be parameterized as function of the average scaled selection coefficient:
\begin{align}
	\omega & = \dfrac{S}{1 - \e^{-S}} \text{, where }\\
	& \Rightarrow	\begin{dcases}
						 S > 0 \iff \omega > 1 \\
						 S = 0 \iff \omega = 1 \\
						 S < 0 \iff \omega < 1
	\end{dcases}
\end{align}

Altogether, the $61$-by-$61$ \gls{codon} \gls{substitution} matrix of \citet{Muse1994} is defined entirely by the mutation matrix ($\Mutmatrix$), $\omega$ and the genetic code:
\begin{equation}
	\begin{dcases}
		\submatrix_{\itoj} & = 0 \text{ if $\ci$ and $\cj$ are not one mutation away} \\
		\submatrix_{\itoj} & = \mutmatrix_{\nucitoj} \text{ if $\ci$ and $\cj$ are syonymous} \\
		\submatrix_{\itoj} & = \omega \mutmatrix_{\nucitoj} \text{ if $\ci$ and $\cj$ are non-syonymous} \\
		\submatrix_{\ci, \ci} & = - \sum\limits_{\cj \neq \ci} \submatrix_{\itoj}
	\end{dcases}
	\label{eq:codon-models}
\end{equation}

It is important to note that under this model, the equilibrium frequencies of all \glspl{codon} are equal, and depends only on the equilibrium frequencies of nucleotides ($\sigma_{A}, \sigma_{C}, \sigma_{G}, \sigma_{T}$):
\begin{align}
	\pi_{\ci} & = \dfrac{\sigma_{\ci[1]}\sigma_{\ci[2]}\sigma_{\ci[3]}}{\sum\limits_{\cj}\sigma_{\cj[1]}\sigma_{\cj[2]}\sigma_{\cj[3]} } \\
	& = \dfrac{\sigma_{\ci[1]}\sigma_{\ci[2]}\sigma_{\ci[3]}}{(1 - \sigma_{T}\sigma_{A}\sigma_{A} - \sigma_{T}\sigma_{A}\sigma_{G} - \sigma_{T}\sigma_{G}\sigma_{A} )},
\end{align}
where $\ci[1]$ denotes the nucleotide at position $1$ of \gls{codon} $i$.

$\bullet$ This model predicts that the nucleotide composition is the same for all $3$ positions of the \glspl{codon}, however it as empirically been observed that the nucleotide composition are not indentical;

$\bullet$ Another approach is 3x4 model which is not mechanistically justified.

Moreover, the relative \gls{substitution} rate at equilibrium $\langle \nu \rangle$ defined by equation \ref{eq:relative-sub-rate}, if restricted to the subset of \glspl{non-synonymous}, identifies to $\omega$:
\begin{align}
	\langle \nu \rangle & = \dfrac{ \sum\limits_{\ci} \pi_{\ci} \sum\limits_{\cj \in \NonSyn_{\ci}} Q_{\itoj}}{\sum\limits_{\ci} \pi_{\ci} \sum\limits_{\cj \in \NonSyn_{\ci}} \mu_{\itoj}} \\
	& = \dfrac{ \sum\limits_{\ci} \pi_{\ci} \sum\limits_{\cj \in \NonSyn_{\ci}} \omega \mu_{\itoj}}{\sum\limits_{\ci} \pi_{\ci} \sum\limits_{\cj \in \NonSyn_{\ci}} \mu_{\itoj}} \\
	& = \omega \dfrac{ \sum\limits_{\ci} \pi_{\ci} \sum\limits_{\cj \in \NonSyn_{\ci}} \mu_{\itoj}}{\sum\limits_{\ci} \pi_{\ci} \sum\limits_{\cj \in \NonSyn_{\ci}} \mu_{\itoj}} \\
	& = \omega,
\end{align}
where $\NonSyn_{\ci}$ is the set of non-synonymous \glspl{codon} neighbors to \gls{codon} $\ci$.
This identity seems so far trivial and unnecessary, but will bear importance later when comparing this phenomenological model to mechanistic models of \gls{codon} \glspl{substitution}.

\subsection{Mechanistic {codon} models}

In the light of protein biophysics, modeling specific amino-acids physico-chemical properties is a crucial ingredient to represent evolution of protein coding \acrshort{DNA} sequences.
In contrast, classical \gls{codon} models aggregate into a single parameter $\omega$ all amino-acid selective constrains, where such constrains are intuitively not equivalent for all mutations.
Classical \gls{codon} model parametrization with a single parameter $\omega$ is equivalent to saying the probability of reaching fixation is the same for any non-synonymous mutation, regardless of the original and mutated amino-acid encoded by the \gls{codon}.
Ultimately, this assumption results in a lack of sensitivity of models seeking deviation from neutrality, since both positive and negative selection are untangled into the same parameter~\citep{Rodrigue2008a}.

In contrast, mechanistic models assume that the protein-coding sequence is at mutation-selection balance under a fixed fitness landscape, which is itself characterized by a fitness vector over the $20$ amino-acid at each site~\citep{Yang2008, Halpern1998, Rodrigue2010}.
Crucially, the probability of fixation depends on the difference of fitness between the amino-acid encoded by the mutated \gls{codon} ($\fitj$) and the fitness of the amino-acid encoded by the original \gls{codon} ($\fiti$), where $\aai$ denotes the amino-acid encoded by \gls{codon} $i$.
The rate of \gls{substitution} from \gls{codon} $\ci$ to $\cj$ is derived from equation \ref{eq:sub-transion-rates}:
\begin{align}
	\submatrix_{\itoj} & = \mu_{\itoj} \dfrac{4 \Ne \left({\fitj - \fiti}\right)}{{1 - \e^{4 \Ne \left({\fiti - \fitj}\right)} }}, \\
	& = \mu_{\itoj} \dfrac{\Fitj - \Fiti}{1 - \e^{\Fiti - \Fitj} }.
\end{align}

Altogether, the $61$-by-$61$ \gls{codon} \gls{substitution} matrix of mechanistic \gls{codon} models is defined entirely by the mutation matrix ($\Mutmatrix$), the vector of $20$ amino-acid relative fitness ($\Fit$) and the genetic code:
\begin{equation}
	\begin{dcases}
		\submatrix_{\itoj} & = 0 \text{ if $\ci$ and $\cj$ are non neighbors} \\
		\submatrix_{\itoj} & = \mu_{\itoj} \text{ if $\ci$ and $\cj$ are syonymous} \\
		\submatrix_{\itoj} & = \mu_{\itoj} \dfrac{\Fitj - \Fiti}{1 - \e^{\Fiti - \Fitj} } \text{ if $\ci$ and $\cj$ are non-syonymous} \\
		\submatrix_{\ci, \ci} & = - \sum\limits_{\cj \neq \ci} \submatrix_{\itoj}
	\end{dcases}
	\label{eq:propensities-models}
\end{equation}
Moreover, because the process is time-reversible (see previous chapter), from equation \ref{eq:equilibrium-mut-sel}, the stationary distribution equals:
\begin{align}
	\pi_{\ci} & = \dfrac{\sigma_{\ci[1]}\sigma_{\ci[2]}\sigma_{\ci[3]}\e^{\Fiti}}{\sum\limits_{\cj}\sigma_{\cj[1]}\sigma_{\cj[2]}\sigma_{\cj[3]}\Fitj }
\end{align}

From a dynamical perspective, a non-synonymous mutation from a \gls{codon} with high fitness to another \gls{codon} will have a low probability of fixation, since the mutated \gls{codon} will have a lower fitness.
At equilibrium this low probability of fixation of the other \gls{codon} result into high frequency of the \gls{codon} with high fitness.
Essentially, at equilibrium the \gls{codon} frequencies only fluctuate at the mutation-selection balance, and all the mutations are \gls{neutral} on average, but slightly deleterious or advantageous, hence the name \gls{nearly-neutral} models~\citep{Ohta1973, Ohta1992, Rodrigue2016}.

The specific case of a flat fitness landscape for all amino-acids, with neither a peak nor a valley results in \gls{neutral} evolution where \gls{substitution} rates equal to mutation rates (see equation \ref{eq:sub-equal-mut}).
In contrast, in \gls{nearly-neutral} models, the amino-acids have a fitness landscape fixed in time, but that is not flat with peak and valley.
The difficulty and complexity of \gls{nearly-neutral} models are to estimate the underlying amino-acid fitness landscape~\citep{Halpern1998}.

Because of computational complexity, mechanistic models consider multiplicative fitness (additive log-fitness) across sites.
A first approximation of \gls{nearly-neutral} models is that all the positions of the sequence share the same amino-acid preferences.
But it has been rapidly recognized that each site in the \gls{codon} sequence should have its own independent \gls{codon} preferences.
Site-specific amino-acid preferences have been estimated either by maximum \gls{likelihood}~\citep{Tamuri2012,Tamuri2014}, by experimental means~\citep{Bloom2017}, or in a Bayesian context have been estimated using non-parametric
prior distribution with \gls{Dirichlet-process}~\citep{Rodrigue2010, Rodrigue2014}.
Fitting the mutation-selection model on a sequence alignment, via equation (\ref{eq:propensities-models}), results to an estimation of the nucleotide mutation rate matrix as well as the fitness landscape of the protein at each site of the sequence.

\subsection{Relationship to classical models}

Mechanistic mutation-selection \gls{codon} models display the important feature of genuinely accounting for purifying selection.
Indeed \citet{Spielman2015} showed mathematically that if the underlying process is \gls{nearly-neutral} \gls{substitution}, the $\dnds$ estimated by the model seeking deviation from neutrality will always be lower than $1$, under the assumption of no \gls{codon} usage bias.
In other word, classical \gls{codon} \gls{substitution} model will interpret a \gls{nearly-neutral} model as purifying selection ($\dnds < 1$).

Indeed, the site-specific predicted rate of non-synonymous over \gls{synonymous} at the mutation-selection balance is obtained as:
\begin{equation}
	\omega_0 = \dfrac{ \sum\limits_{i} \pi_{i} \sum\limits_{j \in \NonSyn_{\ci}} \dfrac{\Fitj - \Fiti}{1 - \e^{\Fiti - \Fitj} }}{\sum\limits_{i} \pi_{i} \sum\limits_{j \in \NonSyn_{\ci} } \mu_{\itoj}},
\end{equation}
where $\NonSyn_{\ci}$ is the set of non-synonymous \glspl{codon} neighbors to \gls{codon} $\ci$.

Even thought classical \gls{codon} models have less parameters than mechanistic \gls{codon} model, it is important to realize they are not nested, such that is impossible to find a given set of parameters for which the two models are equivalent.
They are inherently different, mechanistic models assume a fixed fitness landscape, while classical models assume a fixed selective effect.
The difference is better highlighted in the case of reverse mutations, where a negative selection coefficient of a mutation is always matched by a positive selection coefficient for the reverse mutation in mechanistic \gls{codon} models.
However in classical \gls{codon} models, a negative selection coefficient is matched by an also a negative selection coefficient for the reverse mutation.

Realizing this relationship between classical and mechanistic \gls{codon} models, under the assumption that the protein is under a \gls{nearly-neutral} regime, the predicted $\omega_0$ (mutation-selection model) and the estimated $\dnds$ (classical-model) should be the same~\citep{Spielman2015, Spielman2016}.
But assumptions of the models can be broken, resulting in difference between $\omega_0$ and $\dnds$.
Firstly, if amino-acids are under a fluctuating fitness landscape, which is known as a Red-Queen process.
In this case, by definition, the protein sequence is tracking a constantly moving fitness optimum.
Since the protein sequence is always lagging behind the moving target defined by the amino acid preferences, and since \glspl{substitution} are accepted preferentially if they are in the direction of this target, \glspl{substitution} are on average adaptive.
In other word, at the moment of a \gls{substitution} the target amino-acid as a high relative fitness, which can only then decreases trough time.
Thus breaking the assumption of time independence of amino-acid preferences leads to $\dnds \geq \omega_0$.

Secondly, the \gls{nearly-neutral} assumption can also be broken if there is no independence between sites, a phenomenon known as epistasis between sites.
Unfortunately, one consequence of epistatic interactions is that even if a mutation is \gls{nearly-neutral} upon fixation, subsequently fixed mutations on other sites make the original \gls{substitution} more and more deleterious to revert over time~\citep{Gong2014, Lunzer2010, Mccandlish2013}.
This effect leads to entrenchment such that instead of lagging behind a moving target, the current amino-acids reinforce its relative fitness.
In other word, at the moment of a \gls{substitution} the target amino-acid has a nearly equal relative fitness, which can only increases with time~\citep{Goldstein2016, Goldstein2017}.
Thus, breaking the assumption of independence between sites leads to $\dnds \leq \omega_0$~\citep{Rodrigue2016}.
To summarize, a departure from near-neutrality with a $\dnds \geq \omega_0$ is a signature of an ongoing Red-Queen process and that the protein is under ever changing adaptation.
On the other hand, a $\dnds \leq \omega_0$ is a signature of epistatic interaction between amino-acids.
But one shortcoming of \gls{nearly-neutral} \gls{codon} \gls{substitution} models is that if one does not get a statistical departure from near-neutrality ($\dnds = \omega_0$), it could be due to a mixture of both Red-Queen and epistatic processes that cannot be untied.

\textcolor{GREEN}{[To integrate :
A new parameter-rich structure-aware mechanistic model for amino acid {substitution} during evolution~\citep{Chi2018}.
Site-Specific Amino Acid Preferences Are Mostly Conserved in Two Closely Related Protein Homologs~\citep{Doud2015}]}


\section{Likelihood of the data}
\label{sec-intro:likelihood}

For a dataset of protein-coding \acrshort{DNA} sequences, the goal is to determine the probability of the observed sequence data at the tips of the tree conditional upon the evolutionary model, the tree, and values of parameters in the model.
The challenge is that only the data for the extant species are observed whereas the sequence at the root of the tree and the subsequent evolutionary events are not directly observed.
In other words, all possible trajectories leading to the observed alignment must be integrated, weighted by their respective probabilities.

Throughout this development, the tree topology ($\tau$) is considered know and fixed.
This restriction emanates that the scope of this is work is not to infer the topology, but the parameters of evolution.
Moreover, the development does not delves into the details of how alignment are obtained, and thus assume that they are correct.
However it has been shown that outputs of different sequence alignment methods tend to produce different results that are not consistent.
The main determining factor of alignment accuracy is evolutionary divergence, such that if alignment are restricted to orthologs from closely related taxa, or to slow-evolving genes, alignment errors become scarce and may not cause significant encumbrance.
Finally, and not the least, models of sequence change will assume that changes at one sequence position have no impact on whether other positions will change.
This assumption of independence between sites allows the probability of an observed set of aligned sequences at the tips of an evolutionary tree to be expressed as the product over alignment columns of the observed nucleotides or amino acids in those columns. 
This independence assumption is simplistic, throwing away biological information, and can be shown statistically to be problematic, but permits computationally convenient likelihood-based inference.

The section is divided into first integrating over all trajectory over a single branch of tree, and subsequently over the total tree. And finally efficiently computing the probability of observed data given the parameters.

\subsection{Probability of {transitions} for a branch at a given site}
Point \gls{substitution} process define the instantaneous rates of change between the different \glspl{codon} through the \gls{substitution} matrix $\Submatrix$.
However, given a starting state of the process (ancestral) and a given amount of time for which the \gls{substitution} process runs, it is possible to derive the probability of the descendant sequence having each of the $61$ \gls{codon} states.
In practice, time is measured in unit of branch length, expressing the expected number of changes to have occurred since the ancestor if {transition} are \gls{neutral}.
For example of branch length of $2$ imply that $2$ changes are expected to be seen on average along the branch under the condition that \glspl{substitution} are \gls{neutral}.
Consequently, the \gls{substitution} rate matrix must be normalized to be measured in unit of branch length, where in practice instead of normalizing the \gls{codon} subtitution matrix, the nucleotide mutation matrix is normalized since mutation are considered \gls{neutral}.
The mathematical details of this transformation from rate-matrix to probability matrix are described from first order derivation of the Markov process.
At a give site ($\site$) of the sequence, and along a given branch ($\branch$) with branch length $\branchlength\branchexp$, the \gls{codon} probability matrix $\Probmatrix\siteexp(\branchlength\branchexp)$ is related to the {transition} matrix ($\Submatrix\siteexp$ at site $\site$) trough the first-order differential equation:
\begin{align}
	\dfrac{\der \Probmatrix\siteexp(\branchlength\branchexp)}{\der \branchlength\branchexp}	& = \Probmatrix\siteexp(\branchlength\branchexp) \Submatrix\siteexp, \\
	\iff \Probmatrix\siteexp(\branchlength\branchexp) & = \e^{\branchlength\branchexp \Submatrix\siteexp}.
\end{align}
The integration of the \gls{substitution} rate matrix over the branch length entails to take into all possible trajectories histories of evolutionary events, leading to a compact probability matrix computed as an exponential of the rate matrix.
In practive, exponential of the rate matrix is usually performed using eigenvalues and eigenvectors decomposition.

\subsection{Total probability of transition}
The challenge to generalize from branch to tree is that only the data at the tips of the tree are observed whereas the states of the internal nodes are not directly observed.
As a result, \gls{likelihood} of the observed data can be readily calculated if the ancestral state of all internal node is know, from the probabilities of {transitions} along each branch of the tree.
As an example for better readability, a simple illustrative tree given in figure \ref{fig:tree} will be used \gls{prior} to giving to general formulas.
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=0.6cm and 1.2cm,semithick]
	\tikzstyle{every state}=[]

	\node[state] (1) [BLUE] {$\state_1$};
	\node[state] (0) [YELLOW, below right=of 1] {$\state_0$};
	\node[state] (2) [BLUE,below left=of 0] {$\state_2$};
	\node[state] (5) [YELLOW,right=of 0] {$\state_5$};
	\node[state] (3) [BLUE,above right=of 5] {$\state_3$};
	\node[state] (4) [BLUE,below right=of 5] {$\state_4$};

	\path[-]
	(1) edge [black] node [above right] {$\branchlength^{(1)}$} (0)
	(2) edge [black] node [below right] {$\branchlength^{(2)}$} (0)
	(5) edge [black] node [above] {$\branchlength^{(5)}$} (0)
	(5) edge [black] node [above left] {$\branchlength^{(3)}$} (3)
	(5) edge [black] node [below left] {$\branchlength^{(4)}$} (4);
	\end{tikzpicture}
	\caption[Illustrative phylogenetic tree]{
	Illustrative phylogenetic tree. Internal nodes ($\state_0$ and $\state_5$) are represented in yellow, while extant nodes ($\state_1$ to $\state_4$) for which the state is know from the observed data is represented in blue. The node $0$ is considered the root of the tree, although defining is not strictly required since the process is reversible.}
	\label{fig:tree}%
\end{figure}

In the example of the illustrated tree, from the observed data for the extant nodes $\Data\siteexp = \{ \state_1,\state_2, \state_3, \state_4 \}$, at site $\site$, the \gls{likelihood} given that the states of the internal nodes are known is computed as:
\begin{align}
	p\left(\Data\siteexp| \state_0, \state_5, \Submatrix\siteexp, \branchlength\branchexp, \forall \branch \right) & = \Probmatrix\siteexp_{\state_0, \state_1}(\branchlength^{(1)})
	\Probmatrix\siteexp_{\state_0, \state_2}(\branchlength^{(2)}) \\
	& \quad \quad \quad
	\times \Probmatrix\siteexp_{\state_5, \state_3}(\branchlength^{(3)})
	\Probmatrix\siteexp_{\state_5, \state_4}(\branchlength^{(4)})
	\Probmatrix\siteexp_{\state_0, \state_5}(\branchlength^{(5)}) \notag
\end{align}
In the general topology, $\Data\siteexp = \{ \state_P \hdots \state_{2P-1} \}$, where $\state_{\nodeUp}$ and $\state_{\nodeDown}$ are used to denoted the respectively the parent and descendant nodes of a branch, the \gls{likelihood} of the observed data is given as:
\begin{align}
p\left(\Data\siteexp| \state_{I}, \Submatrix\siteexp, \branchlength\branchexp, \forall (I, \branch) \right) & = \prod_{b} \Probmatrix\siteexp_{\state_{\nodeDown}, \state_{\nodeUp}}(\branchlength^{(\branch)}),
\end{align}
where $I$ runs over all the internal nodes.

Because the states of the internal nodes are not actually unknown, the \gls{likelihood} must be summed over the all the possible states, weighted by their equilibrium stationary frequencies ($\pi\siteexp$).

In the case of the illustrative example, the total probability is given as
\begin{align}
	p\left(\Data\siteexp| \Submatrix\siteexp, \branchlength\branchexp , \forall \branch \right) & = \sum\limits_{\state_0=1}^{61} \subequi_{\state_0} \sum\limits_{\state_5=1}^{61} \subequi_{\state_5} p\left(\Data\siteexp| \state_0, \state_5, \Submatrix\siteexp, \branchlength\branchexp \right) \\
	& = \sum\limits_{\state_0=1}^{61} \subequi_{\state_0} \sum\limits_{\state_5}^{61} \subequi_{\state_5} \Probmatrix\siteexp_{\state_0, \state_1}(\branchlength^{(1)})
	\Probmatrix\siteexp_{\state_0, \state_2}(\branchlength^{(2)}) \\
	& \qquad \qquad \qquad
	\times \Probmatrix\siteexp_{\state_5, \state_3}(\branchlength^{(3)})
	\Probmatrix\siteexp_{\state_5, \state_4}(\branchlength^{(4)})
	\Probmatrix\siteexp_{\state_0, \state_5}(\branchlength^{(5)})\notag
\end{align}

And because the process is reversible, the equilibrium frequencies of \glspl{codon} satisfies the equations:
\begin{align}
\bm{0} & = \bm{\pi}\branchsiteexp \Submatrix\branchsiteexp \\
\iff \bm{\pi}\branchsiteexp & = \bm{\pi}\branchsiteexp \Probmatrix\branchsiteexp \\
\iff \dfrac{\subequi_{\ci}\siteexp}{\subequi_{\cj}\siteexp} & = \dfrac{\submatrix_{\cj, \ci}\siteexp}{\submatrix_{\ci, \cj}\siteexp}
\end{align}

In the general topology, the \gls{likelihood} of the observed data is thus given as:
\begin{align}
p\left(\Data\siteexp| \Submatrix\siteexp, \branchlength\branchexp, \forall \branch \right) & = p\left(\Data\siteexp| \state_{I}, \Submatrix\siteexp, \branchlength\branchexp, \forall (I, \branch) \right), \\
& = \sum\limits_{\state_{0}=1}^{61} \subequi_{\state_{0}} \hdots \sum\limits_{\state_{k}=1}^{61} \subequi_{\state_{k}} \prod_{b} \Probmatrix\siteexp_{\state_{\branch^{+}}, \state_{\branch^{-}}}(\branchlength^{(\branch)}), \label{eq:likelihood-site}
\end{align}

And finally, the assumption of independence between sites allows the probability of an observed set of aligned sequences at the tips of an evolutionary tree to be expressed as the product over alignment columns of the observed nucleotides or amino acids in those columns:
\begin{align}
p\left(\Data| \Submatrix\siteexp, \branchlength\branchexp, \forall (\site, \branch) \right) & = \prod_{\site} p\left(\Data\siteexp| \Submatrix\siteexp, \branchlength\branchexp, \forall \branch \right) \label{eq:likelihood}
\end{align} 
\subsection{Pruning algorithm}
The \gls{likelihood} of observed data at a specific column of a multiple sequence alignment, given by equation \ref{eq:likelihood} requires extensive computation, but can however can be determined with the pruning algorithm of \citet{Felsenstein1985}. 
The \gls{likelihood} of the data $\Data$ can be computed using the pruning algorithm:
\begin{align}
p\left(\Data\siteexp| \Submatrix\siteexp, \branchlength\branchexp, \forall \branch \right) & = \sum\limits_{\ci=1}^{61} \subequi\siteexp_{\ci} \pruning\siteexp_{0} \left( \ci \right)
\end{align}
where $\pruning_{\node} \left( \ci \right)$ is computed recursively from the $2$ descendant children $\node_{1}$ and $\node_{2}$ of an internal node $\node$:
\begin{align}
\pruning\siteexp_{\node} \left( \ci \right) = 
\left[ \sum\limits_{\cj=1}^{61}\Probmatrix\siteexp_{\itoj}(\branchlength^{(\node \to \node_{1})}) \pruning\siteexp_{\node_{1}} \left( \cj \right) \right]
\cdot 
\left[ \sum\limits_{\cj=1}^{61}\Probmatrix\siteexp_{\itoj}(\branchlength^{(\node \to \node_{2})}) \pruning\siteexp_{\node_{2}} \left( \cj \right) \right]
\end{align}
And if the node $\node$ is a node with no descendant, meaning an extant taxa:
\begin{align}
\pruning\siteexp_{\node} \left( \ci \right) =
\begin{dcases}
1, & \text{if } \state_{\node} = \ci \\
0, & \text{otherwise.}
\end{dcases}
\end{align}

\section{Bayesian estimation}
\label{sec-intro:bayesian}

The Bayesian Paradigm can be seen as a way to model uncertainty in a probabilistic way.
In other words, parameter of the models denoted $\theta$ are considered as random variables whose distribution describes that uncertainty.
This unconditional distribution of parameters, $p(\theta)$, is called the \gls{prior}.
The probability of those parameters are going to be modified after acquisition of information supplied by observed data.

$\bullet$ Why has Bayesian statistics been used in phylogenetic inference \citep{Lartillot2020}.

Knowingly that maximum \gls{likelihood} and Bayesian statistics are often opposed to each others and sometimes fiercely defended by their tenant, using one of them implicitly put someone in the position to argument their choice.
Firstly, Bayesian statistics technically is not required to devise procedure necessary to evades local optimums.
Second and most importantly, Bayesian statistics output not a single statistic but a confidence interval, meaning how much certainty is available given the data.
Posterior and \gls{prior} can be thus presented next to each others and differences between the two is due to signal extracted from the data.
A corollary is that over parametrization is not such a drastic issue as in maximum \gls{likelihood} inference, since in a case where there is only limited extractable signal from the data this will reflect in the confidence interval.
In the worst possible case of over-parametrization, namely that of confounded parameters, such that the model is exactly the same for different set of parameters, the confidence interval will expand but confounded parameters can be identified afterward through parameters correlation in their joint \gls{posterior} distribution.
The subjective arbitrary introduced by lasso and penalized-likelihood is replaced by statistical \gls{prior} distribution.
However, over-parameterized models is still a misappropriate use of computing resource, which results in a greater environmental cost.

Formally, Bayes theorem is essential in updating of the distribution :
\begin{equation}
	p(\theta|\data)=\frac{p(\data|\theta)p(\theta)}{p(\data)}
\end{equation}
The probability of the parameters matrix $\theta$ given the data is called the \gls{posterior} probability, it is \gls{posterior} to the data, and $p(\data|\Probmatrix)$ is the 

Because the actual probability of the data is not going to change, in inference Bayes theorem is often presented as:
\begin{equation}
p(\data|\data) \propto p(\data|\data)p(\data)
\end{equation}
Simply stating that the \gls{posterior} is proportional to the \gls{likelihood} time the \gls{prior}.

From the \gls{likelihood} of the data derived in the previous section, the difficulties now is shifted to the definition of the \gls{prior} distribution, where these difficulties come in two flavors.
Firstly, the parameters of evolution for which \gls{prior} distribution can be apprehended might be the parameters of interest such as the selection coefficient, or on the mutation rate, but not the \gls{prior} distribution of the \gls{substitution} rate matrix as a whole.
This difficulties is eased by Bayesian network, which are a probabilistic graphical representation of a set of variables and their conditional dependencies via a directed acyclic graph (DAG).
In the example of the \gls{prior} distribution for the rate \gls{substitution} matrix, it is determined as the joint distribution of the \gls{prior} over the selection coefficient and the mutation rate matrix, which itself is given by the joint distribution over the equilibrium frequencies of nucleotides and exchangeabilities rates for the general-time-reversible (GTR) mutation matrix (see figure \ref{fig:DAG}).
Seeing the DAG the other way around (following the arrows), simple \gls{prior} distribution are combined together to form more complex joint \gls{prior} distribution which ultimately define the \gls{prior} distribution of the model ($\theta$).

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=0.6cm and 1.2cm,semithick]
	\tikzstyle{every state}=[]
	
	\node[state] (P) {$\Probmatrix\siteexp(\branchlength\branchexp)$};
	\node[state] (Q) [below right=of P] {$\Submatrix\siteexp$};
	\node[state] (BL) [BLUE, above right=of P] {$\branchlength\branchexp$};
	\node[state] (Exp) [RED, right=of BL] {$1$};
	\node[state] (F) [below right=of Q] {$\bm{F}\siteexp$};
	\node[state] (sb) [BLUE, right=of F] {$W$};
	\node[state] (sbH) [RED, right=of sb] {$\stickbreakinghyper$};
	\node[state] (R) [above right=of Q] {$\Mutmatrix$};
	\node[state] (Ex) [BLUE, above right=of R] {$\Exchan$};
	\node[state] (ExH) [RED, right=of Ex] {$\dfrac{1}{6}, 6$};
	\node[state] (Equi) [BLUE, below right=of R] {$\Mutequi$};
	\node[state] (EquiH) [RED, right=of Equi] {$\dfrac{1}{4}, 4$};
	
	\path 
	(Q) edge [black] node [above right] {} (P)
	(BL) edge [black] node [] {} (P)
	(Exp) edge [dashed, BLUE] node [above] {\textit{Exp}} (BL)
	(R) edge [black] node {} (Q)
	(Ex) edge [black] node [] {} (R)
	(Equi) edge [black] node [below] {} (R)
	(ExH) edge [dashed, BLUE] node [above] {\textit{Dir}} (Ex)
	(EquiH) edge [dashed, BLUE] node [above] {\textit{Dir}} (Equi)
	(F) edge [black] node {} (Q)
	(sb) edge [black] node [above] {} (F)
	(sbH) edge [dashed, BLUE] node [above] {\textit{DP}} (sb);
	\end{tikzpicture}
	\caption[Directed acyclic graph of Bayesian network]{
	Directed acyclic graph of dependencies between variables.
	Nodes of the directed acyclic graph are the variables, and edges are the functions. Hyper-parameters are depicted in {\color{RED}{red}} circle, random variables in {\color{BLUE}{blue}} circles, and transformed variables in black.
	{\color{BLUE}{blue}} solid line denotes a drawing from a random distribution, and black solid lines denote a function.
	\textit{Exp} denotes an exponential distribution, \textit{Dir} denotes a Dirichlet distribution, and finally \textit{DP} denotes a \gls{Dirichlet-process}.}
	\label{fig:DAG}
\end{figure}

Secondly, once realizing that the \gls{prior} distribution can be boiled to a set of simpler \gls{prior} distributions, the difficulty arise from the high dimensionality of the parameter space, known as the curse of dimensionality.
More precisely, the number of states increases exponentially with the number of dimension of the space, such that the space is too large to be explored and computation of both the \gls{prior} and the \gls{likelihood} for each set of parameters is unrealistic.
Reduction in the exploration of the state space is obtained by employing Monte-Carlo Markov-Chain, which effectively approximate the target \gls{posterior} distribution.

\subsection{Monte-Carlo Markov-Chain}

The first \acrshort{MC} algorithm is associated with the army laboratory in Los Alamos under the direction of Metropolis in early 1952.
Both a physicist and a mathematician, Nicolas Metropolis was one of the first scientists to work on the Manhattan Project that led to the production of the atomic bomb.
Almost as early, he became obsessed with the hydrogen bomb, which he eventually succeed in building.

Published in June 1953 in the \textit{Journal of Chemical Physics}, the primary focus of \acrshort{MC} algorithm is computing the energy of random configurations for a system of many particles.
This energy is not not available analytically and requires integration across for all realizations of the random configurations of the particle system.
Because the number of dimensions is high (twice the number of particles), numerical integration is impossible using a deterministic algorithm.
Moreover, because the probability of a given configuration can be very small, even Monte Carlo integration, by sampling randomly across the target distribution of configurations fails to correctly approximate this integral.

This problem can however be transposed in the \gls{mc} realm, where each state of the process is a particular configuration of particles.
The {transition} probabilities between states must generate a stationary distribution equal to the target distribution of particle configurations.
Given this requirement, and given we can also sample from the {transition} probabilities, the Monte Carlo \gls{mc} starts from a given state and can be updated by random sampling from the {transition} probabilities.
The chain is composed of a period of burn-in, where the current state is of low probability relative to more likely states.
Once reaching the dynamic equilibrium, the energy of each configuration can be computed and the average of this energy is an approximate solution for the integral of energy over the distribution of configurations.

\subsection{Metropolis-Hastings sampling}

The Metropolis algorithm is an acceptance/rejection rule for the probabilities of {transition} allowing to match the stationary distribution to the specified target distribution, present in the original paper.
From a state $X_t$, the algorithm proceeds as follows at each step of the \gls{mc}:
\begin{itemize}
	\item Generate a random candidate state $X'$ according to $g(X'\mid X_t)$.
	\item Calculate the acceptance ratio $\displaystyle r=\min \left(1,{\frac {P(X')}{P(X_{t})}}{\frac {g(X_{t}\mid X')}{g(X'\mid X_{t})}}\right)$.
	\item Generate a uniform random number $u\in [0,1]$.
	If $u\leq A(X',X_{t})$, then accept the new state and set $X_{t+1}=X'$.
	Else reject the new state and set $X_{t+1}=X$
\end{itemize}

The algorithm requires the ability to calculate the acceptance ratio $r$ for all possible jump, and to draw a jump from any state. 
In addition, last step above requires the generation of a uniform random number.
The Metropolis procedure has been developped in the context of a symmetric distribution $g(X'\mid X) = g(X \mid X')$, and was later generalized to incorporate any distribution, such that the factor $g(X'\mid X) / g(X \mid X')$ took the name Hasting ratio.

\subsection{Gibbs sampling}

Gibbs sampling is applicable when a joint distribution of variables is not known explicitly or is difficult to sample from directly, but the conditional distribution of each variable are easier to sample from.
The original implementation of the Gibbs sampler was applied to a discrete image processing problem, a problem somewhat removed from statistical inference in the classical sense.
This paper is also responsible for the name {\it Gibbs sampling}, because it implemented this method for the Bayesian study of {\it Gibbs random fields} which, in turn, derive their name from the physicist Josiah Willard Gibbs (1839-1903).

The individual variables are sampled one at a time, with each variable conditioned on the most recent values of all the others.
It can be shown that the sequence of samples constitutes a \gls{mc}, and the stationary distribution of that \gls{mc} is just the joint distribution.
Gibbs sampling is particularly well-adapted to sampling the \gls{posterior} distribution of a Bayesian network, since they are composed of a set of individual random variables in which each variable is conditioned on only a small number of other variables.

Gibbs sampling can be considered a general framework for sampling from a large set of variables by sampling each variable (or in some cases, each group of variables) in turn.
Various algorithms can be used to sample these individual variables, depending on the exact form of the multivariate distribution, it can incorporate the Metropolis–Hastings algorithm, or more sophisticated methods such as slice sampling, adaptive rejection sampling and adaptive rejection Metropolis.

\subsection{Sufficient statistics \& data augmentation}

The basic idea is to augment the observed sequence data with a possible \gls{substitution} history and to then use \gls{mc} Monte Carlo techniques to perform a random walk over histories that are consistent with the observed data.

A realization of the random process results in a detailed \gls{substitution} history over the tree.
Most phylogenetic Monte-Carlo-Markov-Chain (\acrshort{MC}) samplers target the distribution over the model parameters, which means that they have to repeatedly invoke the pruning algorithm to recalculate
the pruning-based \gls{likelihood} which is most often the limiting step of the \acrshort{MC}.

An alternative, which is used here, is to do the \acrshort{MC} conditionally on the detailed \gls{substitution} history $\subhistory$, thus doing the \acrshort{MC} over the augmented configuration~($\subhistory$, $\data$), under the target distribution obtained by combining the mapping-based \gls{likelihood} with the \gls{prior} over model parameters

The key idea that makes this strategy efficient is that the mapping-based \gls{likelihood} depends on
compact summary statistics of $\subhistory$ (which in turn depend on the specific parameter component
being resampled), leading to very fast evaluation of the \gls{likelihood}.
On the other hand, this requires to implement more complex \acrshort{MC} procedures, that have to alternate between:

1) sampling $\subhistory$ conditionally on the data and the current parameter configuration.

2) re-sampling the parameters conditionally on $\subhistory$.

To implement the mapping-based \acrshort{MC} sampling strategy, we first sample the detailed \gls{substitution} history $\subhistory$ for all sites along the tree.
Several methods exist for doing this~\citep{Nielsen2002,Rodrigue2008}.
Then, we write down the probability of $\subhistory$ given the parameters, and finally, we collect all factors that depend on some parameter of interest and make some simplifications.
This ultimately leads to relatively compact sufficient statistics (Supplementary Materials for the different sufficient statistics used by our model) that are fast to evaluate~\citep{Irvahn2014,Davydov2016}.

\subsection{Implementation}

$\bullet$ The work developped in this manuscript

$\bullet$ Modularity of the code, JAGS, MrBayes, RevBayes and now BayesCode,
\url{https://github.com/bayesiancook/bayescode}